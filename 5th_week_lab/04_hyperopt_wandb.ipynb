{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Copyright\n",
    "\n",
    "<PRE>\n",
    "This notebook was created as part of the \"Deep learning / VITMMA19\" class at\n",
    "Budapest University of Technology and Economics, Hungary,\n",
    "https://portal.vik.bme.hu/kepzes/targyak/VITMMA19\n",
    "\n",
    "Any re-use or publication of any part of the notebook is only allowed with the\n",
    " written consent of the authors.\n",
    "\n",
    "2025 (c) Mohammed Salah Al-Radhi and Tamás Gábor Csapó (malradhi@tmit.bme.hu)\n",
    "</PRE>"
   ],
   "metadata": {
    "id": "F1qzWtl3IKEb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "### HYPEROPT: task during the class - we will do this together\n",
    "# add WandB.ai integration to the code\n",
    "# (help: https://docs.wandb.ai/guides/integrations/lightning )\n",
    "# run at least 3 different trainings"
   ],
   "metadata": {
    "id": "yXJibCILHkgW"
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ylmHRNZuexnE"
   },
   "outputs": [],
   "source": [
    "# install pytorch lithening\n",
    "!pip install pytorch-lightning --quiet\n",
    "!pip install wandb --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5dPxEJZwe6Y2"
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CczgZ5nkgAGy"
   },
   "outputs": [],
   "source": [
    "# create one class to deal with data\n",
    "class CifarDataModule(pl.LightningDataModule):\n",
    "  def __init__(self, batch_size, data_dir=\"./\"):\n",
    "    super().__init__()\n",
    "    self.data_dir=data_dir\n",
    "    self.batch_size=batch_size\n",
    "    self.transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "    self.num_classes=10\n",
    "\n",
    "  def prepare_data(self):\n",
    "    CIFAR10(self.data_dir,train=True,download=True)\n",
    "    CIFAR10(self.data_dir,train=False,download=True)\n",
    "\n",
    "  def setup(self, stage=None):\n",
    "    if stage=='fit' or stage is None:\n",
    "      cifar_full=CIFAR10(self.data_dir,train=True,transform=self.transform)\n",
    "      self.cifar_train,self.cifar_val=random_split(cifar_full,[45000,5000])\n",
    "\n",
    "    if stage=='test' or stage is None:\n",
    "      self.cifar_test=CIFAR10(self.data_dir,train=False,transform=self.transform)\n",
    "\n",
    "  def train_dataloader(self):\n",
    "    return DataLoader(self.cifar_train,batch_size=self.batch_size,shuffle=True,num_workers=2)\n",
    "\n",
    "  def val_dataloader(self):\n",
    "    return DataLoader(self.cifar_val,batch_size=self.batch_size,shuffle=False,num_workers=2)\n",
    "\n",
    "  def test_dataloader(self):\n",
    "    return DataLoader(self.cifar_test,batch_size=self.batch_size,shuffle=False,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-Xal7kSzlkAb"
   },
   "outputs": [],
   "source": [
    "class CIFAR10LitModel(pl.LightningModule):\n",
    "    def __init__(self, input_shape,num_classes,learning_rate=3e-4):\n",
    "      super().__init__()\n",
    "      self.save_hyperparameters()\n",
    "      self.input_shape=input_shape\n",
    "      self.learning_rate=learning_rate\n",
    "\n",
    "      # model architecture\n",
    "      self.conv1=nn.Conv2d(3,32,3,1)\n",
    "      self.conv2=nn.Conv2d(32,32,3,1)\n",
    "      self.conv3=nn.Conv2d(32,64,3,1)\n",
    "      self.conv4=nn.Conv2d(64,64,3,1)\n",
    "      self.pool1=nn.MaxPool2d(2)\n",
    "      self.pool2=nn.MaxPool2d(2)\n",
    "\n",
    "      n_sizes = self._get_output_shape(input_shape)\n",
    "      self.fc1=nn.Linear(n_sizes,512)\n",
    "      self.fc2=nn.Linear(512,128)\n",
    "      self.fc3=nn.Linear(128,num_classes)\n",
    "\n",
    "      self.train_acc=Accuracy(task='multiclass',num_classes=10)\n",
    "      self.val_acc=Accuracy(task='multiclass',num_classes=10)\n",
    "      self.test_acc=Accuracy(task='multiclass',num_classes=10)\n",
    "\n",
    "\n",
    "    def _get_output_shape(self, shape):\n",
    "          '''returns the size of the output tensor from the conv layers'''\n",
    "          batch_size = 1\n",
    "          input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
    "          output_feat = self._feature_extractor(input)\n",
    "          n_size = output_feat.data.view(batch_size, -1).size(1)\n",
    "          return n_size\n",
    "\n",
    "\n",
    "  # conv1,relu, conv2,relu, maxpool,conv3,relu,conv4,relu,maxpool\n",
    "    def _feature_extractor(self,x):\n",
    "      x=F.relu(self.conv1(x))\n",
    "      x=self.pool1(F.relu(self.conv2(x)))\n",
    "      x=F.relu(self.conv3(x))\n",
    "      x=self.pool2(F.relu(self.conv4(x)))\n",
    "      return x\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "      x=self._feature_extractor(x)\n",
    "      x=x.view(x.size(0),-1)\n",
    "      x=F.relu(self.fc1(x))\n",
    "      x=F.relu(self.fc2(x))\n",
    "      x=F.log_softmax(self.fc3(x),dim=1)\n",
    "      return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "      x, y = batch\n",
    "      logits = self(x)\n",
    "      loss = F.nll_loss(logits, y)\n",
    "      # metric\n",
    "      preds = torch.argmax(logits, dim=1)\n",
    "      acc = self.train_acc(preds, y)\n",
    "      self.log('train_loss', loss, on_step=True, on_epoch=True, logger=True)\n",
    "      self.log('train_acc', acc, on_step=True, on_epoch=True, logger=True)\n",
    "      return loss\n",
    "\n",
    "    # validation loop\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "      x, y = batch\n",
    "      logits = self(x)\n",
    "      loss = F.nll_loss(logits, y)\n",
    "      preds = torch.argmax(logits, dim=1)\n",
    "      acc = self.val_acc(preds, y)\n",
    "      self.log('val_loss', loss, prog_bar=True)\n",
    "      self.log('val_acc', acc, prog_bar=True)\n",
    "      return loss\n",
    "\n",
    "    # test loop\n",
    "    def test_step(self,batch,batch_idx):\n",
    "      x,y=batch\n",
    "      logits=self(x)\n",
    "      loss=F.nll_loss(logits,y)\n",
    "\n",
    "      pred=torch.argmax(logits,dim=1)\n",
    "      acc=self.test_acc(pred,y)\n",
    "      self.log('test_loss',loss,on_epoch=True)\n",
    "      self.log('test_acc',acc,on_epoch=True)\n",
    "      return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "      optimizer=torch.optim.Adam(self.parameters(),self.learning_rate)\n",
    "      return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "IRAcw-MZYebS"
   },
   "outputs": [],
   "source": [
    "# class for visualizing one batch of validation images along with predicted and rall class label\n",
    "class ImagePredictionLogger(pl.Callback):\n",
    "    def __init__(self, val_samples, num_samples=32):\n",
    "        super().__init__()\n",
    "        self.val_imgs, self.val_labels = val_samples\n",
    "        self.val_imgs = self.val_imgs[:num_samples]\n",
    "        self.val_labels = self.val_labels[:num_samples]\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        val_imgs = self.val_imgs.to(device=pl_module.device)\n",
    "        logits = pl_module(val_imgs)\n",
    "        preds = torch.argmax(logits, 1)\n",
    "\n",
    "        trainer.logger.experiment.log({\n",
    "            \"examples\": [wandb.Image(x, caption=f\"Pred:{pred}, Label:{y}\")\n",
    "                            for x, pred, y in zip(val_imgs, preds, self.val_labels)],\n",
    "            \"global_step\": trainer.global_step\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R7kOEzHpmCYi",
    "outputId": "15e7b18e-3ffc-4116-cba3-960278537cff"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the cifar and model\n",
    "cifar = CifarDataModule(batch_size=32)\n",
    "cifar.prepare_data()\n",
    "cifar.setup()\n",
    "\n",
    "# Grab samples to log predictions on\n",
    "samples = next(iter(cifar.val_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "pbTicSoZ1Gtw"
   },
   "outputs": [],
   "source": [
    "### WandB, you have have an account(if you don't, create one)\n",
    "def train_model(learning_rate=1e-3):\n",
    "    wandb.login(key='')\n",
    "    config=wandb.config\n",
    "    wandb_logger = WandbLogger(project='lastt', job_type='train', log_model=\"all\")\n",
    "    # instantiate classes\n",
    "    dm = CifarDataModule(32)\n",
    "    dm.prepare_data()\n",
    "    dm.setup()\n",
    "    model = CIFAR10LitModel((3, 32, 32), dm.num_classes, learning_rate)\n",
    "    wandb_logger.watch(model)\n",
    "    # Initialize Callbacks\n",
    "    checkpoint_callback = pl.callbacks.ModelCheckpoint()\n",
    "    early_stop_callback = pl.callbacks.EarlyStopping(monitor=\"val_acc\", patience=3, verbose=False, mode=\"max\")\n",
    "    ### WandB\n",
    "    trainer = pl.Trainer(max_epochs=5,\n",
    "                     logger=wandb_logger,\n",
    "                     callbacks=[checkpoint_callback, early_stop_callback,ImagePredictionLogger(samples)]\n",
    "                    )\n",
    "    # Train the model\n",
    "    trainer.fit(model, dm)\n",
    "\n",
    "    # Evaluate the model\n",
    "    trainer.test(dataloaders=cifar.test_dataloader())\n",
    "    # tell the WandB you have finished\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Start training the model\n",
    "train_model()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "c1168a6e207d44cbb185efaca620a538",
      "eab91f57b5a54fa1bef3ce80af07f64a",
      "c1a2fb89632f4cdcb7f5efd52afda248",
      "49956a7cf2e74999b682f57f558d8634",
      "e35fe51a0cc54295afb7bca8832136e7",
      "b47d59ca4a674d34b27f215476729039",
      "448008429b5246eea4c22b3918cec0fc",
      "01e92be1d18f411e942aec4463181ac4",
      "71acad37daeb4b519b9edca6a6609672",
      "6fe1d99be20e4a3a8c5376533320c9b7",
      "1c8c8a47ae45436aabd02a843b34c711",
      "37d44a58635646768f0f04dc3a854722",
      "35c628301a244740af714c920933bc3b",
      "55ccb44eebe1479e97ff594aaea9130f",
      "7323cbfe6da94cbbbae6c47eea3478bc",
      "1ab071cb115d44d1b6ffbd5a4d52a5b0",
      "3ca5ff6e21964062bef6b61025c24d92",
      "e127c72fc4234eb1b214df83fa366718",
      "e1f3dc54a505413cb0fed764da24a501",
      "14fa7b1df06d4929b5adc44f6a90d5b3",
      "7b4a28b943484822ad543138a1f571af",
      "4980b648e18a4952bd4f4f4647e231ea",
      "da8b03d1c62a4dd8a42734c101d33e2f",
      "689695cf398847378285258d16e93564",
      "d9795f1602604a6db989cfb0a6221d9c",
      "8e5d4f89f4664560bf97d8f8e8ea167c",
      "9bceab8533314cb29b7136266ef41d1b",
      "cc61c2f2444c4dbb90de8cdc1b3e010b",
      "de6b44cc3585437492974855f0d7bd15",
      "755319f9edd94b32836e71aa14483281",
      "a56c169d0bbd4817bd0edb6ce35e6354",
      "e9b8bf8c1ad049f9abfaddd866be2244",
      "62b4a6fb00fe4efaa9f4770ebfee2515",
      "edf933271cf0408ebb6d4da7ea059fb5",
      "5cad2ce23f4245eab1bae34b3cdcf540",
      "2228cdfa39c84c6093e13acdf492c772",
      "db5548b737e34d8a88f3bf78cffb0278",
      "54d664aedd0a4d44a4ef4d6cfd0ccbf2",
      "7e4889842a9048459ccd6490dbf384b5",
      "32e65ccb466948f7a871a483c70bb504",
      "6d61fc462d3549598a72a704232d815b",
      "d46b292a0fa745af85c62f0b72d49b96",
      "405ebddc8ad3481c8853db82eb10b55b",
      "d958607c60c4457e9c56ca78917f3d41",
      "0474386ef61b49cdaf76724ff722b8bb",
      "7f5e1d6580454ffa8171cc9372eda968",
      "da24e94e2ad8417e8eef24af55dce8f3",
      "c72ac542178c4b0498bb67d9f0b5c9c4",
      "e38dd969ee3a48b98ff106693d50a5aa",
      "99cc92049fb8447a8b772321617b9866",
      "9131364e3be7453d8e751b177cd05f47",
      "081a371b6545457dad0c1cbe6ecef42c",
      "865e9dacd158468591b176ed47477b77",
      "371a2f19b584428f96441565c208a7f4",
      "6e43a1ce449d4446abc7a76be03f7096",
      "88c805959b0e41ceb51a42d62fb39af3",
      "d3a9a8740e2e42f49e7772a92302104d",
      "e1f699fa3c724de89753ec04936f93e8",
      "45fa84b6487d4f7caf335eae0d793e00",
      "39969711958f4d2696428d6edb6a98bb",
      "0132400124784a9d91ebae5b4bb457a5",
      "d075bfb7641549cc9dae5beea9d969bc",
      "62cf28394ac74f34bf4159e55a205550",
      "e946e6ba453543feb309882117525faa",
      "712d42a2e952449fbc8d9fd81f81bafb",
      "f6fb5aad53214945b0fe4c2ad66ddda7",
      "11747c2ff20b4950ba096652797848b9",
      "ed66deaa53204cf4a42e27ee5aa4e291",
      "88802c03aed34c4582e4c083c9fee43c",
      "8133197edd364ac89f4f21d912947b81",
      "54539143d0354d57a367ef4efe2fc781",
      "3a1dd4ac918e42f38058207f2973689e",
      "9a8f363c5a704c0992afecb6fcc9c5fa",
      "3482504ca239481db01c1eea5748686c",
      "aa840780f906421cad38e9668c6a768c",
      "2216d0b5754a4200a603f6ffeafecc9e",
      "37012ac8859745dcbf161c4028b99460",
      "ec746faa8b5a44cf822d95923eb94015",
      "a34afe69f2894b9696bb6d914dae1fb4",
      "12fb5cb363fa4c1eba4612b47556fbeb",
      "2c508d837de343b785ea0dab99408eb2",
      "85e9e71dc2b04a0a80780d452bc190a7",
      "7a3bb0e8298945f99970384077fb4f89",
      "16d3902affd643ed8b86074c47169318",
      "7d08ce111c764ecba926c7f8b245147b",
      "605e0f53a1104aca888e56e3deda1d57",
      "436a31124af94463b130a2866632c903",
      "3af81b6d64ee4b6ab05a5e8673801473",
      "679ec5dd2940402aa8357b696b24598f",
      "4cdc9f0698374ec982aff1d371e13197",
      "a474d7ca93e5417ab7df3d2627316b69",
      "05bb5182ee61482a9c0a0eb3f02ebc00",
      "e87a32d80147494183ac26d86d356676",
      "c74cd1ffc1a049f79d7d37d1e9ee34dd",
      "de57f3d2cb3c48bb881c7f09ca823239",
      "b90ff82dfdb84960b083a35af182ea12"
     ]
    },
    "id": "YUkC7oRTcV8_",
    "outputId": "e1c15370-89b6-4010-f2e3-bd478935b8dc"
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33meng-bme-2017\u001b[0m (\u001b[33meng-bme-2017-bme\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.18.2"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20240930_194446-8xie57nk</code>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eng-bme-2017-bme/lastt/runs/8xie57nk' target=\"_blank\">eager-wildflower-4</a></strong> to <a href='https://wandb.ai/eng-bme-2017-bme/lastt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/eng-bme-2017-bme/lastt' target=\"_blank\">https://wandb.ai/eng-bme-2017-bme/lastt</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/eng-bme-2017-bme/lastt/runs/8xie57nk' target=\"_blank\">https://wandb.ai/eng-bme-2017-bme/lastt/runs/8xie57nk</a>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "   | Name      | Type               | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0  | conv1     | Conv2d             | 896    | train\n",
      "1  | conv2     | Conv2d             | 9.2 K  | train\n",
      "2  | conv3     | Conv2d             | 18.5 K | train\n",
      "3  | conv4     | Conv2d             | 36.9 K | train\n",
      "4  | pool1     | MaxPool2d          | 0      | train\n",
      "5  | pool2     | MaxPool2d          | 0      | train\n",
      "6  | fc1       | Linear             | 819 K  | train\n",
      "7  | fc2       | Linear             | 65.7 K | train\n",
      "8  | fc3       | Linear             | 1.3 K  | train\n",
      "9  | train_acc | MulticlassAccuracy | 0      | train\n",
      "10 | val_acc   | MulticlassAccuracy | 0      | train\n",
      "11 | test_acc  | MulticlassAccuracy | 0      | train\n",
      "----------------------------------------------------------\n",
      "952 K     Trainable params\n",
      "0         Non-trainable params\n",
      "952 K     Total params\n",
      "3.809     Total estimated model params size (MB)\n",
      "12        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c1168a6e207d44cbb185efaca620a538"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "37d44a58635646768f0f04dc3a854722"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da8b03d1c62a4dd8a42734c101d33e2f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "edf933271cf0408ebb6d4da7ea059fb5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0474386ef61b49cdaf76724ff722b8bb"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "88c805959b0e41ceb51a42d62fb39af3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "11747c2ff20b4950ba096652797848b9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Restoring states from the checkpoint path at ./lastt/8xie57nk/checkpoints/epoch=4-step=7035.ckpt\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:pytorch_lightning.utilities.rank_zero:Loaded model weights from the checkpoint at ./lastt/8xie57nk/checkpoints/epoch=4-step=7035.ckpt\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec746faa8b5a44cf822d95923eb94015"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7228000164031982    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8428255915641785    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7228000164031982     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8428255915641785     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='55.056 MB of 55.056 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "679ec5dd2940402aa8357b696b24598f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▃▃▃▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆██████████</td></tr><tr><td>global_step</td><td>▁▂▄▅▇█</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▅▆▇█</td></tr><tr><td>train_acc_step</td><td>▂▁▁▅▅▅▅▃▆▆▆▆▆▆▅▇▇▆▆▆▆█▅▆▇▇▇▅▇██▆▇▆▅█▇▇█▅</td></tr><tr><td>train_loss_epoch</td><td>█▅▃▂▁</td></tr><tr><td>train_loss_step</td><td>██▇▅▇▅▅▆▅▄▃▅▄▅▄▄▃▄▄▄▄▆▄▁▃▂▄▁▂▃▁▄▁▁▁▂▃▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇████</td></tr><tr><td>val_acc</td><td>▁▅▇██</td></tr><tr><td>val_loss</td><td>█▄▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>global_step</td><td>7035</td></tr><tr><td>test_acc</td><td>0.7228</td></tr><tr><td>test_loss</td><td>0.84283</td></tr><tr><td>train_acc_epoch</td><td>0.78553</td></tr><tr><td>train_acc_step</td><td>0.6875</td></tr><tr><td>train_loss_epoch</td><td>0.61224</td></tr><tr><td>train_loss_step</td><td>0.783</td></tr><tr><td>trainer/global_step</td><td>7035</td></tr><tr><td>val_acc</td><td>0.7272</td></tr><tr><td>val_loss</td><td>0.82051</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">eager-wildflower-4</strong> at: <a href='https://wandb.ai/eng-bme-2017-bme/lastt/runs/8xie57nk' target=\"_blank\">https://wandb.ai/eng-bme-2017-bme/lastt/runs/8xie57nk</a><br/> View project at: <a href='https://wandb.ai/eng-bme-2017-bme/lastt' target=\"_blank\">https://wandb.ai/eng-bme-2017-bme/lastt</a><br/>Synced 5 W&B file(s), 0 media file(s), 10 artifact file(s) and 193 other file(s)"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20240930_194446-8xie57nk/logs</code>"
      ]
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "### TASK OF THE STUDENT\n",
    "\n",
    "# extend WandB.ai integration in the code with sweeps\n",
    "# (e.g. add variables like learning rate, optimizer, neurons_FC1, neurons_FC2)\n",
    "# help: https://docs.wandb.ai/guides/sweeps and\n",
    "#       https://github.com/wandb/wandb/issues/5003\n",
    "# store the hyperparameters and val_acc to wandb\n",
    "# run at least 10 trainings\n",
    "# in wandb.ai, export the result of the runs as a .csv file,\n",
    "# in wandb.ai, create a report from the sweep results and share it by submitting\n",
    "# the link in Moodle."
   ],
   "metadata": {
    "id": "Kah5L02HLalv"
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "c3PXlgbpZbEh"
   },
   "execution_count": 10,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}